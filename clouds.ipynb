{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "clouds.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SomgBird/Certificate/blob/master/clouds.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GdUIOsMKXgh1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "!pip install -q kaggle\n",
        "!mkdir ~/.kaggle\n",
        "!cp ./kaggle.json ~/.kaggle\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "!mkdir clouds\n",
        "!kaggle competitions download -c understanding_cloud_organization\n",
        "!unzip train.csv.zip\n",
        "!mv train.csv ./clouds/train.csv\n",
        "!unzip test_images.zip -d ./clouds/test_images\n",
        "!unzip train_images.zip -d ./clouds/train_images\n",
        "!rm *.zip\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PS-wXYmoFt9V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import gc\n",
        "import os\n",
        "from pathlib import Path\n",
        "import matplotlib.pyplot as plt\n",
        "import keras\n",
        "import cv2\n",
        "from collections import defaultdict\n",
        "from skimage.data import imread\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras import backend as K\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "import json\n",
        "\n",
        "path=Path('./clouds')\n",
        "os.listdir(path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zOZ-XjTJQfNV",
        "colab_type": "text"
      },
      "source": [
        "<h1>Data analysis</h1>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LhaQKKwxXFXJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train=pd.read_csv(path/'train.csv')\n",
        "train.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WdfaEbwdG3J3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hzdlEXUHRlRv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train['ImageId']=train['Image_Label'].apply(lambda x : x.split('_')[0])\n",
        "train['cat']=train['Image_Label'].apply(lambda x : x.split('_')[1])\n",
        "train[train['EncodedPixels'].notnull()].head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZoO6-q5jRvxw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cat=train[train['EncodedPixels'].notnull()]['cat'].value_counts()\n",
        "plt.bar(cat.index, cat)\n",
        "plt.xlabel('category of cloud')\n",
        "plt.ylabel('number of masked samples')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_IRaEECWR1EQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x1=train[train['EncodedPixels'].notnull()].shape[0]\n",
        "x2=train[train['EncodedPixels'].isnull()].shape[0]\n",
        "plt.bar(['has Mask','not Masked'],[x1,x2])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iNX_cw_JSErJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train['has_mask']= ~pd.isna(train['EncodedPixels'])\n",
        "train['missing']= pd.isna(train['EncodedPixels'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ux4FaTXnSL8x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_nan=train.groupby('ImageId').agg('sum')\n",
        "train_nan.columns=['No: of Masks','Missing masks']\n",
        "train_nan['Missing masks'].hist()\n",
        "\n",
        "mask_count_df=pd.DataFrame(train_nan)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A7BU8zPrXXH6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mask_count_df = train.groupby('ImageId').agg(np.sum).reset_index()\n",
        "mask_count_df.sort_values('has_mask', ascending=False, inplace=True)\n",
        "print(mask_count_df.shape)\n",
        "mask_count_df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PrCS_dbZXarn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_nan['No: of Masks'].hist()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fwYw7aCUXfC2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image_size=defaultdict(int)\n",
        "image_file=path/'train_images'\n",
        "for img in image_file.iterdir():\n",
        "    img=Image.open(img)\n",
        "    image_size[img.size]+=1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lVVG3_osXcek",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image_size"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MJkhxJLgXf13",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image_size=defaultdict(int)\n",
        "image_file=path/'test_images'\n",
        "for img in image_file.iterdir():\n",
        "    img=Image.open(img)\n",
        "    image_size[img.size]+=1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "de2JK3BAXi6S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image_size"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F1iBZp6OXkrs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "no_patterns=0\n",
        "patterns=0\n",
        "\n",
        "for i in range(0,len(train),4):\n",
        "    samples=[x.split('_')[0] for x in train.iloc[i:i+4,0].values]\n",
        "    if(samples[0]!=samples[1]!=samples[2]!=samples[3]):\n",
        "        raise ValueError\n",
        "    labels=train.iloc[i:i+4]['EncodedPixels']\n",
        "    if labels.isna().all():\n",
        "        no_patterns+=1\n",
        "    else:\n",
        "        patterns+=1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ohtY2PjRXl99",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('Number of images with patters {} '.format(patterns))\n",
        "print(\"Number of images without patters {} \".format(no_patterns))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OiolTuSZXnUa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "labels = sorted(list(set(train['Image_Label'].apply(lambda x: x.split('_')[1]))))\n",
        "print(labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BPaR6RqDXpgr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def rle_decode(mask,shape=(1400,2100)):\n",
        "    \n",
        "    s=mask.split()\n",
        "    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n",
        "    starts-=1\n",
        "    end=starts+lengths\n",
        "    img=np.zeros(shape[0]*shape[1],dtype=np.uint8)\n",
        "    for l,m in zip(starts,end):\n",
        "        img[l:m]=1\n",
        "    return img.reshape(shape[0],shape[1],order='F')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nRiNIRaxXp1s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_nan[train_nan['No: of Masks']==4].iloc[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BVIXqOSsXrFz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image_name = '00dec6a.jpg'\n",
        "img = imread(str(path)+'/train_images/' + image_name)\n",
        "\n",
        "fig, ax = plt.subplots(2, 2, figsize=(15, 10))\n",
        "\n",
        "for e, label in enumerate(labels):\n",
        "    axarr = ax.flat[e]\n",
        "    image_label = image_name + '_' + label\n",
        "    mask_rle = train.loc[train['Image_Label'] == image_label, 'EncodedPixels'].values[0]\n",
        "    try: # label might not be there!\n",
        "        mask = rle_decode(mask_rle)\n",
        "    except:\n",
        "        mask = np.zeros((1400, 2100))\n",
        "    axarr.axis('off')\n",
        "    axarr.imshow(img)\n",
        "    axarr.imshow(mask, alpha=0.5, cmap='gray')\n",
        "    axarr.set_title(label, fontsize=24)\n",
        "plt.tight_layout(h_pad=0.1, w_pad=0.1)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7EORN6WArIH4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import albumentations as albu"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VwNkCOvZSPao",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def np_resize(img, input_shape):\n",
        "    \"\"\"\n",
        "    Reshape a numpy array, which is input_shape=(height, width), \n",
        "    as opposed to input_shape=(width, height) for cv2\n",
        "    \"\"\"\n",
        "    height, width = input_shape\n",
        "    return cv2.resize(img, (width, height))\n",
        "    \n",
        "def mask2rle(img):\n",
        "    '''\n",
        "    img: numpy array, 1 - mask, 0 - background\n",
        "    Returns run length as string formated\n",
        "    '''\n",
        "    pixels= img.T.flatten()\n",
        "    pixels = np.concatenate([[0], pixels, [0]])\n",
        "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
        "    runs[1::2] -= runs[::2]\n",
        "    return ' '.join(str(x) for x in runs)\n",
        "\n",
        "def rle2mask(rle, input_shape):\n",
        "    width, height = input_shape[:2]\n",
        "    \n",
        "    mask= np.zeros( width*height ).astype(np.uint8)\n",
        "    \n",
        "    array = np.asarray([int(x) for x in rle.split()])\n",
        "    starts = array[0::2]\n",
        "    lengths = array[1::2]\n",
        "\n",
        "    current_position = 0\n",
        "    for index, start in enumerate(starts):\n",
        "        mask[int(start):int(start+lengths[index])] = 1\n",
        "        current_position += lengths[index]\n",
        "        \n",
        "    return mask.reshape(height, width).T\n",
        "\n",
        "def build_masks(rles, input_shape, reshape=None):\n",
        "    depth = len(rles)\n",
        "    if reshape is None:\n",
        "        masks = np.zeros((*input_shape, depth))\n",
        "    else:\n",
        "        masks = np.zeros((*reshape, depth))\n",
        "    \n",
        "    for i, rle in enumerate(rles):\n",
        "        if type(rle) is str:\n",
        "            if reshape is None:\n",
        "                masks[:, :, i] = rle2mask(rle, input_shape)\n",
        "            else:\n",
        "                mask = rle2mask(rle, input_shape)\n",
        "                reshaped_mask = np_resize(mask, reshape)\n",
        "                masks[:, :, i] = reshaped_mask\n",
        "    \n",
        "    return masks\n",
        "\n",
        "def build_rles(masks, reshape=None):\n",
        "    width, height, depth = masks.shape\n",
        "    \n",
        "    rles = []\n",
        "    \n",
        "    for i in range(depth):\n",
        "        mask = masks[:, :, i]\n",
        "        \n",
        "        if reshape:\n",
        "            mask = mask.astype(np.float32)\n",
        "            mask = np_resize(mask, reshape).astype(np.int64)\n",
        "        \n",
        "        rle = mask2rle(mask)\n",
        "        rles.append(rle)\n",
        "        \n",
        "    return rles"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mHBHETL9vjsT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install catalyst\n",
        "from catalyst.dl import utils\n",
        "import albumentations as albu\n",
        "from catalyst.dl import utils\n",
        "from albumentations import torch as AT"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YwYF2sQMv_1i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_training_augmentation():\n",
        "    train_transform = [\n",
        "\n",
        "        albu.HorizontalFlip(p=0.5),\n",
        "        albu.ShiftScaleRotate(scale_limit=0.5, rotate_limit=0, shift_limit=0.1, p=0.5, border_mode=0),\n",
        "        albu.GridDistortion(p=0.5),\n",
        "        albu.OpticalDistortion(p=0.5, distort_limit=2, shift_limit=0.5),\n",
        "        albu.Resize(320, 640)\n",
        "    ]\n",
        "    return albu.Compose(train_transform)\n",
        "\n",
        "def get_validation_augmentation():\n",
        "    \"\"\"Add paddings to make image shape divisible by 32\"\"\"\n",
        "    test_transform = [\n",
        "        albu.Resize(320, 640)\n",
        "    ]\n",
        "    return albu.Compose(test_transform)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4PxT7bBbVA78",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DataGenerator(keras.utils.Sequence):\n",
        "    'Generates data for Keras'\n",
        "    def __init__(self, list_IDs, df, target_df=None, mode='fit',\n",
        "                 base_path='./clouds/train_images',\n",
        "                 batch_size=32, dim=(1400, 2100), n_channels=3, reshape=None,\n",
        "                 n_classes=4, random_state=2019, shuffle=True,\n",
        "                 transforms = albu.Compose([albu.HorizontalFlip(p=0.5),\n",
        "                                            albu.RandomContrast(limit=0.2, p=0.5),\n",
        "                                            albu.RandomGamma(gamma_limit=(80, 120), p=0.5),\n",
        "                                            albu.ShiftScaleRotate(\n",
        "                                                shift_limit=0.0625, \n",
        "                                                scale_limit=0.1,\n",
        "                                                rotate_limit=15, \n",
        "                                                border_mode=cv2.BORDER_REFLECT_101, \n",
        "                                                p=0.8),\n",
        "                                            albu.ToFloat(max_value=255)\n",
        "                                           ])):\n",
        "        \n",
        "        self.dim = dim\n",
        "        self.batch_size = batch_size\n",
        "        self.df = df\n",
        "        self.mode = mode\n",
        "        self.base_path = base_path\n",
        "        self.target_df = target_df\n",
        "        self.list_IDs = list_IDs\n",
        "        self.reshape = reshape\n",
        "        self.n_channels = n_channels\n",
        "        self.n_classes = n_classes\n",
        "        self.shuffle = shuffle\n",
        "        self.random_state = random_state\n",
        "        self.transforms = transforms\n",
        "        self.batch_shape = (self.batch_size,) + self.reshape + (self.n_channels,)\n",
        "        self.mask_batch_shape = (self.batch_size,) + self.reshape + (self.n_classes,)\n",
        "        \n",
        "        self.on_epoch_end()\n",
        "\n",
        "    def __len__(self):\n",
        "        'Denotes the number of batches per epoch'\n",
        "        return int(np.floor(len(self.list_IDs) / self.batch_size))\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        'Generate one batch of data'\n",
        "        # Generate indexes of the batch\n",
        "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
        "\n",
        "        # Find list of IDs\n",
        "        list_IDs_batch = [self.list_IDs[k] for k in indexes]\n",
        "        \n",
        "        imgs = self.__generate_X(list_IDs_batch)\n",
        "        \n",
        "        X = np.ndarray(shape=self.batch_shape)\n",
        "        y = np.ndarray(shape=self.mask_batch_shape)\n",
        "        \n",
        "        if self.mode == 'fit':\n",
        "            masks = self.__generate_y(list_IDs_batch)\n",
        "                    \n",
        "            for img, mask in zip(imgs, masks):\n",
        "                augmented = self.transforms(image=img, mask=mask)\n",
        "                np.append(X, augmented['image'])\n",
        "                np.append(y, augmented['mask'])\n",
        "                \n",
        "            return X, y\n",
        "        elif self.mode == 'predict':\n",
        "            for img in imgs:\n",
        "                augmented = self.transforms(image=img)\n",
        "                np.append(X, augmented['image'])\n",
        "            \n",
        "            return X\n",
        "        else:\n",
        "            raise AttributeError('The mode parameter should be set to \"fit\" or \"predict\".')\n",
        "        \n",
        "    def on_epoch_end(self):\n",
        "        'Updates indexes after each epoch'\n",
        "        self.indexes = np.arange(len(self.list_IDs))\n",
        "        if self.shuffle == True:\n",
        "            np.random.seed(self.random_state)\n",
        "            np.random.shuffle(self.indexes)\n",
        "    \n",
        "    def __generate_X(self, list_IDs_batch):\n",
        "        'Generates data containing batch_size samples'\n",
        "        # Initialization\n",
        "        if self.reshape is None:\n",
        "            X = np.empty((self.batch_size, *self.dim, self.n_channels))\n",
        "        else:\n",
        "            X = np.empty((self.batch_size, *self.reshape, self.n_channels))\n",
        "        \n",
        "        # Generate data\n",
        "        for i, ID in enumerate(list_IDs_batch):\n",
        "            im_name = self.df['ImageId'].iloc[ID]\n",
        "            img_path = f\"{self.base_path}/{im_name}\"\n",
        "            \n",
        "            if self.n_channels == 3:\n",
        "                img = self.__load_rgb(img_path)\n",
        "            else:\n",
        "                img = self.__load_grayscale(img_path)\n",
        "            \n",
        "            if self.reshape is not None:\n",
        "                img = np_resize(img, self.reshape)\n",
        "            \n",
        "            if len(img.shape) == 2:\n",
        "                img = np.expand_dims(img, axis=-1)\n",
        "            \n",
        "            \n",
        "            # Store samples\n",
        "            X[i,] = img\n",
        "\n",
        "        return X\n",
        "    \n",
        "    def __generate_y(self, list_IDs_batch):\n",
        "        if self.reshape is None:\n",
        "            y = np.empty((self.batch_size, *self.dim, self.n_classes), dtype=int)\n",
        "        else:\n",
        "            y = np.empty((self.batch_size, *self.reshape, self.n_classes), dtype=int)\n",
        "        \n",
        "        for i, ID in enumerate(list_IDs_batch):\n",
        "            im_name = self.df['ImageId'].iloc[ID]\n",
        "            image_df = self.target_df[self.target_df['ImageId'] == im_name]\n",
        "            \n",
        "            rles = image_df['EncodedPixels'].values\n",
        "            \n",
        "            if self.reshape is not None:\n",
        "                masks = build_masks(rles, input_shape=self.dim, reshape=self.reshape)\n",
        "            else:\n",
        "                masks = build_masks(rles, input_shape=self.dim)\n",
        "            \n",
        "            y[i, ] = masks\n",
        "\n",
        "        return y\n",
        "    \n",
        "    def __load_grayscale(self, img_path):\n",
        "        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
        "        img = img.astype(np.float32) / 255.\n",
        "        img = np.expand_dims(img, axis=-1)\n",
        "\n",
        "        return img\n",
        "    \n",
        "    def __load_rgb(self, img_path):\n",
        "        img = cv2.imread(img_path)\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "        img = img.astype(np.float32) / 255.\n",
        "\n",
        "        return img"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a0_EKq3RVEpx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def dice_coef(y_true, y_pred, smooth=1):\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred_f = K.flatten(y_pred)\n",
        "    intersection = K.sum(y_true_f * y_pred_f)\n",
        "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
        "\n",
        "def dice_loss(y_true, y_pred):\n",
        "    smooth = 1.\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred_f = K.flatten(y_pred)\n",
        "    intersection = y_true_f * y_pred_f\n",
        "    score = (2. * K.sum(intersection) + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
        "    return 1. - score\n",
        "\n",
        "def bce_dice_loss(y_true, y_pred):\n",
        "    return binary_crossentropy(y_true, y_pred) + dice_loss(y_true, y_pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qlwffNpxVGkX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE = 32\n",
        "\n",
        "train_idx, val_idx = train_test_split(\n",
        "    mask_count_df.index, random_state=2019, test_size=0.15\n",
        ")\n",
        "\n",
        "train_generator = DataGenerator(\n",
        "    train_idx, \n",
        "    df=mask_count_df,\n",
        "    target_df=train,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    reshape=(256, 384),\n",
        "    n_channels=3,\n",
        "    n_classes=4\n",
        ")\n",
        "\n",
        "val_generator = DataGenerator(\n",
        "    val_idx, \n",
        "    df=mask_count_df,\n",
        "    target_df=train,\n",
        "    batch_size=BATCH_SIZE, \n",
        "    reshape=(256, 384),\n",
        "    n_channels=3,\n",
        "    n_classes=4\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8gqUvbHOmaxH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install segmentation_models"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gbYqRZy0VQPp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from segmentation_models import Linknet\n",
        "from segmentation_models.backbones import get_preprocessing\n",
        "\n",
        "preprocess = get_preprocessing('resnet34')\n",
        "model = Linknet('resnet34',\n",
        "                input_shape=(256, 384, 3),\n",
        "                classes=4,\n",
        "                activation='sigmoid')\n",
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=[dice_coef])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JD2MtnyCVZQC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "checkpoint = ModelCheckpoint('/content/drive/My Drive/keras_callbacks/weights-{epoch:02d}-{val_loss:.2f}-{val_dice_coef:.2f}.hdf5', verbose=1, save_best_only=True, mode='min')\n",
        "callbacks_list = [checkpoint]\n",
        "\n",
        "history=model.fit_generator(train_generator,\n",
        "                            validation_data=val_generator,\n",
        "                            epochs=20,\n",
        "                            verbose=1,\n",
        "                            callbacks=callbacks_list)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J-71wHsTipyE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open(path/'history.json', 'w') as f:\n",
        "    json.dump(history.history, f)\n",
        "\n",
        "history_df = pd.DataFrame(history.history)\n",
        "history_df[['loss', 'val_loss']].plot()\n",
        "history_df[['dice_coef', 'val_dice_coef']].plot()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W3wpAnMJy5vx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sub_df = pd.read_csv('sample_submission.csv')\n",
        "sub_df['ImageId'] = sub_df['Image_Label'].apply(lambda x: x.split('_')[0])\n",
        "test_images = pd.DataFrame(sub_df['ImageId'].unique(), columns=['ImageId'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lQSx0KLe1Bng",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save_weights(path/'model_resnet34_linknet.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wx2hNoU-irit",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.load_weights(path/'model_resnet34_linknet.h5')\n",
        "\n",
        "test_df = []\n",
        "n = 300\n",
        "\n",
        "for i in range(0, test_images.shape[0], n):\n",
        "    batch_idx = list(\n",
        "        range(i, min(test_images.shape[0], i + n))\n",
        "    )\n",
        "    \n",
        "    test_generator = DataGenerator(\n",
        "        batch_idx,\n",
        "        df=test_images,\n",
        "        shuffle=False,\n",
        "        mode='predict',\n",
        "        reshape=(256, 384),\n",
        "        n_channels=3,\n",
        "        base_path=path/'test_images',\n",
        "        target_df=sub_df,\n",
        "        batch_size=1,\n",
        "        n_classes=4\n",
        "    )\n",
        "    \n",
        "    batch_pred_masks = model.predict_generator(\n",
        "        test_generator, \n",
        "        workers=1,\n",
        "        verbose=1,\n",
        "        use_multiprocessing=False\n",
        "    )\n",
        "    \n",
        "    for j, b in enumerate(batch_idx):\n",
        "        filename = test_images['ImageId'].iloc[b]\n",
        "        image_df = sub_df[sub_df['ImageId'] == filename].copy()\n",
        "        \n",
        "        pred_masks = batch_pred_masks[j, ].round().astype(int)\n",
        "        pred_rles = build_rles(pred_masks, reshape=(1400, 2100))\n",
        "        \n",
        "        image_df['EncodedPixels'] = pred_rles\n",
        "        test_df.append(image_df)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QMufC8Cn4r-V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_df = pd.concat(test_df)\n",
        "test_df.drop(columns='ImageId', inplace=True)\n",
        "test_df.to_csv(path/'submission.csv', index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CAQnF-PyX9ic",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}